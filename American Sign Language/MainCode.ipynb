{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67b46dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e743e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 1. BASIC CONFIG\n",
    "# ==============================\n",
    "# Use the split dataset\n",
    "DATA_DIR = r\"C:\\Harsh Works\\code\\American Sign Language\\ASL_Split\"\n",
    "\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "VAL_DIR = os.path.join(DATA_DIR, \"val\")\n",
    "TEST_DIR = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "SEED = 42\n",
    "\n",
    "# Output folder for models, plots, CSV\n",
    "OUTPUT_DIR = r\"C:\\Harsh Works\\code\\American Sign Language\\asl_training_outputs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87d69a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2516 files belonging to 6 classes.\n",
      "Found 533 files belonging to 6 classes.\n",
      "Found 533 files belonging to 6 classes.\n",
      "Classes: ['Hello', 'I Love You', 'Okay', 'Please', 'Thank you', 'Yes']\n",
      "Total train batches: 79\n",
      "Baseline train batches (Model 1): 39\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 2. LOAD DATA FROM FOLDERS\n",
    "# ==============================\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    VAL_DIR,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    TEST_DIR,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "# Prefetch for performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.prefetch(AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(AUTOTUNE)\n",
    "\n",
    "\n",
    "# Create smaller training dataset for weaker Model 1\n",
    "train_batches = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "baseline_fraction = 0.5  # try 0.3 or 0.2 if still perfect accuracy\n",
    "\n",
    "limited_train_ds = train_ds.take(int(train_batches * baseline_fraction))\n",
    "\n",
    "print(\"Total train batches:\", train_batches)\n",
    "print(\"Baseline train batches (Model 1):\", int(train_batches * baseline_fraction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fe81717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 3. DATA AUGMENTATION LAYER\n",
    "# ==============================\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.1),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb9e7665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 4. MODEL 1 â€“ SIMPLE CNN\n",
    "# ==============================\n",
    "def build_model_1(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), num_classes=6):\n",
    "    model = models.Sequential([\n",
    "        layers.Rescaling(1./255, input_shape=input_shape),\n",
    "        data_augmentation,\n",
    "\n",
    "        layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "235b9255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 5. MODEL 2 â€“ TRANSFER LEARNING (MobileNetV2)\n",
    "# ==============================\n",
    "def build_model_2(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), num_classes=6):\n",
    "    base_model = keras.applications.MobileNetV2(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "    )\n",
    "    base_model.trainable = False  # freeze base layers\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = layers.Rescaling(1./255)(inputs)\n",
    "    x = data_augmentation(x)\n",
    "    x = base_model(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c25e49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= TRAINING MODEL 1: SIMPLE CNN =================\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\preprocessing\\data_layer.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 207ms/step - accuracy: 0.4960 - loss: 1.2811 - val_accuracy: 0.9212 - val_loss: 0.2575\n",
      "Epoch 2/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.8776 - loss: 0.3670 - val_accuracy: 0.9606 - val_loss: 0.1047\n",
      "Epoch 3/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.9086 - loss: 0.2661 - val_accuracy: 0.9869 - val_loss: 0.0370\n",
      "Epoch 4/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.9304 - loss: 0.2050 - val_accuracy: 0.9831 - val_loss: 0.0373\n",
      "Epoch 5/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.9507 - loss: 0.1498 - val_accuracy: 0.9981 - val_loss: 0.0097\n",
      "Epoch 6/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.9519 - loss: 0.1481 - val_accuracy: 0.9794 - val_loss: 0.0399\n",
      "Epoch 7/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.9567 - loss: 0.1273 - val_accuracy: 0.9981 - val_loss: 0.0074\n",
      "Epoch 8/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 163ms/step - accuracy: 0.9642 - loss: 0.1068 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 9/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.9714 - loss: 0.0904 - val_accuracy: 0.9981 - val_loss: 0.0045\n",
      "Epoch 10/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 168ms/step - accuracy: 0.9690 - loss: 0.0855 - val_accuracy: 0.9512 - val_loss: 0.1265\n",
      "Epoch 11/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 165ms/step - accuracy: 0.9678 - loss: 0.0973 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "Epoch 12/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.9726 - loss: 0.0823 - val_accuracy: 0.9662 - val_loss: 0.0588\n",
      "Epoch 13/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 159ms/step - accuracy: 0.9742 - loss: 0.0734 - val_accuracy: 0.9944 - val_loss: 0.0127\n",
      "Epoch 14/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 160ms/step - accuracy: 0.9618 - loss: 0.1068 - val_accuracy: 0.9981 - val_loss: 0.0030\n",
      "Epoch 15/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 163ms/step - accuracy: 0.9738 - loss: 0.0772 - val_accuracy: 0.9981 - val_loss: 0.0038\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Test Accuracy: 1.0\n",
      "âœ… Model 1 saved as C:\\Harsh Works\\code\\American Sign Language\\asl_training_outputs\\asl_model_cnn.h5\n",
      "\n",
      "================= TRAINING MODEL 2: MobileNetV2 =================\n",
      "Epoch 1/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 167ms/step - accuracy: 0.6975 - loss: 0.8606 - val_accuracy: 0.9287 - val_loss: 0.2547\n",
      "Epoch 2/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 147ms/step - accuracy: 0.9173 - loss: 0.2415 - val_accuracy: 0.9700 - val_loss: 0.1396\n",
      "Epoch 3/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 140ms/step - accuracy: 0.9567 - loss: 0.1467 - val_accuracy: 0.9812 - val_loss: 0.1044\n",
      "Epoch 4/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 151ms/step - accuracy: 0.9710 - loss: 0.1117 - val_accuracy: 0.9831 - val_loss: 0.0817\n",
      "Epoch 5/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 142ms/step - accuracy: 0.9722 - loss: 0.0988 - val_accuracy: 0.9625 - val_loss: 0.1072\n",
      "Epoch 6/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 137ms/step - accuracy: 0.9837 - loss: 0.0711 - val_accuracy: 0.9869 - val_loss: 0.0616\n",
      "Epoch 7/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - accuracy: 0.9781 - loss: 0.0736 - val_accuracy: 0.9887 - val_loss: 0.0541\n",
      "Epoch 8/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - accuracy: 0.9861 - loss: 0.0552 - val_accuracy: 0.9850 - val_loss: 0.0555\n",
      "Epoch 9/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 137ms/step - accuracy: 0.9849 - loss: 0.0540 - val_accuracy: 0.9737 - val_loss: 0.0732\n",
      "Epoch 10/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - accuracy: 0.9889 - loss: 0.0458 - val_accuracy: 0.9794 - val_loss: 0.0632\n",
      "Epoch 11/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 137ms/step - accuracy: 0.9841 - loss: 0.0520 - val_accuracy: 0.9812 - val_loss: 0.0522\n",
      "Epoch 12/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 137ms/step - accuracy: 0.9873 - loss: 0.0458 - val_accuracy: 0.9831 - val_loss: 0.0510\n",
      "Epoch 13/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 143ms/step - accuracy: 0.9877 - loss: 0.0417 - val_accuracy: 0.9794 - val_loss: 0.0555\n",
      "Epoch 14/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 149ms/step - accuracy: 0.9893 - loss: 0.0381 - val_accuracy: 0.9775 - val_loss: 0.0591\n",
      "Epoch 15/15\n",
      "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 157ms/step - accuracy: 0.9924 - loss: 0.0290 - val_accuracy: 0.9737 - val_loss: 0.0646\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.9775 - loss: 0.0709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Test Accuracy: 0.9774859547615051\n",
      "âœ… Model 2 saved as C:\\Harsh Works\\code\\American Sign Language\\asl_training_outputs\\asl_model_mobilenetv2.h5\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 6. TRAIN BOTH MODELS\n",
    "# ==============================\n",
    "EPOCHS = 15\n",
    "# EPOCHS_MODEL1 = 5\n",
    "# EPOCHS_MODEL2 = 15\n",
    "\n",
    "# print(\"\\n================= TRAINING MODEL 1 =================\")\n",
    "# model1 = build_model_1(num_classes=num_classes)\n",
    "# history1 = model1.fit(\n",
    "#     limited_train_ds,          # <-- weaker dataset\n",
    "#     validation_data=val_ds,\n",
    "#     epochs=EPOCHS_MODEL1,\n",
    "# )\n",
    "\n",
    "print(\"\\n================= TRAINING MODEL 1: SIMPLE CNN =================\")\n",
    "model1 = build_model_1(num_classes=num_classes)\n",
    "history1 = model1.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    ")\n",
    "test_loss1, test_acc1 = model1.evaluate(test_ds)\n",
    "print(\"Model 1 Test Accuracy:\", test_acc1)\n",
    "\n",
    "# SAVE MODEL 1\n",
    "model1_path = os.path.join(OUTPUT_DIR, \"asl_model_cnn.h5\")\n",
    "model1.save(model1_path)\n",
    "print(f\"âœ… Model 1 saved as {model1_path}\")\n",
    "\n",
    "\n",
    "print(\"\\n================= TRAINING MODEL 2: MobileNetV2 =================\")\n",
    "model2 = build_model_2(num_classes=num_classes)\n",
    "history2 = model2.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    ")\n",
    "test_loss2, test_acc2 = model2.evaluate(test_ds)\n",
    "print(\"Model 2 Test Accuracy:\", test_acc2)\n",
    "\n",
    "# SAVE MODEL 2\n",
    "model2_path = os.path.join(OUTPUT_DIR, \"asl_model_mobilenetv2.h5\")\n",
    "model2.save(model2_path)\n",
    "print(f\"âœ… Model 2 saved as {model2_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a46215e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= MODEL 1 CLASSIFICATION REPORT =================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Hello     1.0000    1.0000    1.0000        92\n",
      "  I Love You     1.0000    1.0000    1.0000        87\n",
      "        Okay     1.0000    1.0000    1.0000        72\n",
      "      Please     1.0000    1.0000    1.0000       131\n",
      "   Thank you     1.0000    1.0000    1.0000        73\n",
      "         Yes     1.0000    1.0000    1.0000        78\n",
      "\n",
      "    accuracy                         1.0000       533\n",
      "   macro avg     1.0000    1.0000    1.0000       533\n",
      "weighted avg     1.0000    1.0000    1.0000       533\n",
      "\n",
      "\n",
      "================= MODEL 2 CLASSIFICATION REPORT =================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Hello     1.0000    1.0000    1.0000        92\n",
      "  I Love You     1.0000    1.0000    1.0000        87\n",
      "        Okay     1.0000    1.0000    1.0000        72\n",
      "      Please     0.9225    1.0000    0.9597       131\n",
      "   Thank you     1.0000    0.8356    0.9104        73\n",
      "         Yes     0.9873    1.0000    0.9936        78\n",
      "\n",
      "    accuracy                         0.9775       533\n",
      "   macro avg     0.9850    0.9726    0.9773       533\n",
      "weighted avg     0.9791    0.9775    0.9769       533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 7. PREDICTIONS + METRICS\n",
    "# ==============================\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Helper to flatten dataset into arrays\n",
    "def get_true_and_pred_labels(model, dataset):\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in dataset:\n",
    "        all_images.append(images.numpy())\n",
    "        all_labels.append(labels.numpy())\n",
    "\n",
    "    all_images = np.concatenate(all_images, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    preds = model.predict(all_images, verbose=0)\n",
    "    y_pred = np.argmax(preds, axis=1)\n",
    "\n",
    "    return all_labels, y_pred\n",
    "\n",
    "# Get labels/preds for both models on the TEST SET\n",
    "y_true1, y_pred1 = get_true_and_pred_labels(model1, test_ds)\n",
    "y_true2, y_pred2 = get_true_and_pred_labels(model2, test_ds)\n",
    "\n",
    "# All possible class indices (0..num_classes-1)\n",
    "all_labels_indices = list(range(num_classes))\n",
    "\n",
    "print(\"\\n================= MODEL 1 CLASSIFICATION REPORT =================\")\n",
    "print(\n",
    "    classification_report(\n",
    "        y_true1,\n",
    "        y_pred1,\n",
    "        labels=all_labels_indices,\n",
    "        target_names=class_names,\n",
    "        zero_division=0,   # handle any zero-support class\n",
    "        digits=4,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\n================= MODEL 2 CLASSIFICATION REPORT =================\")\n",
    "print(\n",
    "    classification_report(\n",
    "        y_true2,\n",
    "        y_pred2,\n",
    "        labels=all_labels_indices,\n",
    "        target_names=class_names,\n",
    "        zero_division=0,\n",
    "        digits=4,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Macro scores for table\n",
    "def get_macro_scores(y_true, y_pred):\n",
    "    report = classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        labels=all_labels_indices,\n",
    "        target_names=class_names,\n",
    "        output_dict=True,\n",
    "        zero_division=0,\n",
    "    )\n",
    "    precision = report[\"macro avg\"][\"precision\"]\n",
    "    recall = report[\"macro avg\"][\"recall\"]\n",
    "    f1 = report[\"macro avg\"][\"f1-score\"]\n",
    "    return precision, recall, f1\n",
    "\n",
    "prec1, rec1, f1_1 = get_macro_scores(y_true1, y_pred1)\n",
    "prec2, rec2, f1_2 = get_macro_scores(y_true2, y_pred2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60099c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MODEL COMPARISON TABLE ===\n",
      "                   Model  Test Accuracy  Macro Precision  Macro Recall  \\\n",
      "0   Simple CNN (Model 1)       1.000000         1.000000      1.000000   \n",
      "1  MobileNetV2 (Model 2)       0.977486         0.984979      0.972603   \n",
      "\n",
      "   Macro F1-Score  \n",
      "0        1.000000  \n",
      "1        0.977298  \n",
      "ğŸ“„ Results table saved to C:\\Harsh Works\\code\\American Sign Language\\asl_training_outputs\\model_comparison_results.csv\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 8. COMPARISON TABLE (PANDAS DF)\n",
    "# ==============================\n",
    "results_df = pd.DataFrame({\n",
    "    \"Model\": [\"Simple CNN (Model 1)\", \"MobileNetV2 (Model 2)\"],\n",
    "    \"Test Accuracy\": [test_acc1, test_acc2],\n",
    "    \"Macro Precision\": [prec1, prec2],\n",
    "    \"Macro Recall\": [rec1, rec2],\n",
    "    \"Macro F1-Score\": [f1_1, f1_2],\n",
    "})\n",
    "\n",
    "print(\"\\n=== MODEL COMPARISON TABLE ===\")\n",
    "print(results_df)\n",
    "\n",
    "csv_path = os.path.join(OUTPUT_DIR, \"model_comparison_results.csv\")\n",
    "results_df.to_csv(csv_path, index=False)\n",
    "print(f\"ğŸ“„ Results table saved to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26366380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Model 1 (Simple CNN) plots saved as:\n",
      "  C:\\Harsh Works\\code\\American Sign Language\\asl_training_outputs\\model1_accuracy.png\n",
      "  C:\\Harsh Works\\code\\American Sign Language\\asl_training_outputs\\model1_loss.png\n",
      "ğŸ“Š Model 2 (MobileNetV2) plots saved as:\n",
      "  C:\\Harsh Works\\code\\American Sign Language\\asl_training_outputs\\model2_accuracy.png\n",
      "  C:\\Harsh Works\\code\\American Sign Language\\asl_training_outputs\\model2_loss.png\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 9. TRAINING CURVE PLOTS\n",
    "# ==============================\n",
    "def plot_history(history, title_prefix, file_prefix):\n",
    "    acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs_range = range(1, len(acc) + 1)\n",
    "\n",
    "    # Accuracy\n",
    "    plt.figure()\n",
    "    plt.plot(epochs_range, acc, label=\"Train Acc\")\n",
    "    plt.plot(epochs_range, val_acc, label=\"Val Acc\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"{title_prefix} - Accuracy\")\n",
    "    plt.legend()\n",
    "    acc_path = os.path.join(OUTPUT_DIR, f\"{file_prefix}_accuracy.png\")\n",
    "    plt.savefig(acc_path)\n",
    "    plt.close()\n",
    "\n",
    "    # Loss\n",
    "    plt.figure()\n",
    "    plt.plot(epochs_range, loss, label=\"Train Loss\")\n",
    "    plt.plot(epochs_range, val_loss, label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"{title_prefix} - Loss\")\n",
    "    plt.legend()\n",
    "    loss_path = os.path.join(OUTPUT_DIR, f\"{file_prefix}_loss.png\")\n",
    "    plt.savefig(loss_path)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"ğŸ“Š {title_prefix} plots saved as:\\n  {acc_path}\\n  {loss_path}\")\n",
    "\n",
    "plot_history(history1, \"Model 1 (Simple CNN)\", \"model1\")\n",
    "plot_history(history2, \"Model 2 (MobileNetV2)\", \"model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8867ab81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ Confusion matrix saved as C:\\Harsh Works\\code\\American Sign Language\\asl_training_outputs\\model1_confusion.png\n",
      "ğŸ“Œ Confusion matrix saved as C:\\Harsh Works\\code\\American Sign Language\\asl_training_outputs\\model2_confusion.png\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 10. CONFUSION MATRIX PLOTS\n",
    "# ==============================\n",
    "def plot_confusion_matrix(cm, classes, title, filename,\n",
    "                          normalize=False,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, ha=\"right\")\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = \".2f\" if normalize else \"d\"\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(\n",
    "            j,\n",
    "            i,\n",
    "            format(cm[i, j], fmt),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    print(f\"ğŸ“Œ Confusion matrix saved as {filename}\")\n",
    "\n",
    "cm1 = confusion_matrix(y_true1, y_pred1)\n",
    "cm2 = confusion_matrix(y_true2, y_pred2)\n",
    "\n",
    "cm1_path = os.path.join(OUTPUT_DIR, \"model1_confusion.png\")\n",
    "cm2_path = os.path.join(OUTPUT_DIR, \"model2_confusion.png\")\n",
    "\n",
    "plot_confusion_matrix(cm1, class_names, \"Model 1 Confusion Matrix\", cm1_path)\n",
    "plot_confusion_matrix(cm2, class_names, \"Model 2 Confusion Matrix\", cm2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2583893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Bar chart saved as C:\\Harsh Works\\code\\American Sign Language\\asl_training_outputs\\model_metrics_bar.png\n",
      "\n",
      "ğŸ‰ All done! Models, metrics, and plots are saved in: C:\\Harsh Works\\code\\American Sign Language\\asl_training_outputs\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 11. BAR CHART: ACCURACY & F1\n",
    "# ==============================\n",
    "labels_models = [\"Model 1\", \"Model 2\"]\n",
    "acc_values = [test_acc1, test_acc2]\n",
    "f1_values = [f1_1, f1_2]\n",
    "\n",
    "x = np.arange(len(labels_models))\n",
    "width = 0.35\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(x - width/2, acc_values, width, label=\"Accuracy\")\n",
    "plt.bar(x + width/2, f1_values, width, label=\"F1-Score\")\n",
    "plt.xticks(x, labels_models)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.title(\"Final Test Metrics: Model 1 vs Model 2\")\n",
    "plt.legend()\n",
    "bar_path = os.path.join(OUTPUT_DIR, \"model_metrics_bar.png\")\n",
    "plt.savefig(bar_path)\n",
    "plt.close()\n",
    "\n",
    "print(f\"ğŸ“Š Bar chart saved as {bar_path}\")\n",
    "print(\"\\nğŸ‰ All done! Models, metrics, and plots are saved in:\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53c2e72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
